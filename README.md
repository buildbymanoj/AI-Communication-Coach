# ü§ñ AI Communication Coach

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Made with Gradio](https://img.shields.io/badge/Made%20with-Gradio-orange)](https://gradio.app)
[![Powered by OpenAI](https://img.shields.io/badge/Powered%20by-OpenAI-green.svg)](https://openai.com)

An AI-powered application that acts as a personal public speaking advisor. Upload a video of yourself speaking, and the AI will perform a holistic analysis of your communication skills, providing a comprehensive report with actionable feedback to help you improve.

---

## ‚ú® Features

- **Multimodal Analysis:** The coach analyzes both verbal and non-verbal communication channels:
    - **üé≠ Visual Analysis:** Detects facial expressions and emotions through computer vision techniques
    - **üëÅÔ∏è Eye Contact:** Measures how consistently you look at the camera
    - **üìù Speech Analysis:** Transcribes speech and analyzes pacing (WPM), use of filler words, and sentiment
    
- **Comprehensive Reports:** Generate detailed assessments with:
    - **üìä Emotion Distribution:** Visual radar charts showing expression variety
    - **üìà Speech Metrics:** Word count, pace, filler word frequency
    - **üñºÔ∏è Expression Samples:** Visual examples of your different facial expressions
    
- **Actionable Feedback:** Receive personalized suggestions for improvement in:
    - **üó£Ô∏è Speaking Style:** Pace, filler word reduction, speech clarity
    - **üòä Emotional Expression:** Expressiveness, variety, appropriateness
    - **üìπ Camera Presence:** Positioning, eye contact, engagement

## üõ†Ô∏è Tech Stack & Architecture

This project orchestrates several state-of-the-art open-source technologies:

- **Backend:** **Python**
- **AI / Machine Learning:**
    - **Speech Recognition:** `openai-whisper` for accurate speech-to-text
    - **Sentiment Analysis:** Hugging Face `transformers` for text sentiment evaluation
    - **Computer Vision:** `OpenCV` for face detection and expression analysis
- **Visualization:** `matplotlib` for data visualization and charting
- **Frontend Interface:** `gradio` for interactive web UI
- **Media Processing:** `ffmpeg-python` for audio extraction

### System Workflow

The application follows a streamlined data processing pipeline:

```mermaid
graph TD
    A[üé• Video Upload] --> B{Extract Audio};
    B --> C[üéß Audio File];
    A --> D[üéûÔ∏è Video Frames];

    subgraph "Parallel Analysis"
        D --> E[üëÅÔ∏è OpenCV: Facial Analysis & Emotion Detection];
        C --> G[üìù Whisper: Speech-to-Text];
    end

    G --> H[üßê Text Analysis: Pace, Fillers, Sentiment];

    subgraph "Data Integration"
        E --> I{üß† Analysis Engine};
        H --> I;
    end

    I --> J[üìä Generate Visual Reports & Suggestions];
    J --> K[üñ•Ô∏è Display in Gradio Interface];
```

## üöÄ Getting Started

### Prerequisites
- Python 3.8+
- FFmpeg installed on your system

### Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/ai-communication-coach.git
cd ai-communication-coach
```

2. Install the required dependencies:
```bash
pip install -r requirements.txt
```

3. Run the application:
```bash
python app.py
```

The web interface will be available at http://localhost:7860

## üìã Usage Guide

1. **Upload Your Video**: Use the upload button or record directly in your browser
2. **Wait for Processing**: The AI will analyze your video (this may take a few moments)
3. **Review Your Report**: Explore the comprehensive analysis of your presentation
4. **Implement Feedback**: Apply the personalized suggestions to improve your skills

## üîç Analysis Components

The AI Communication Coach provides a detailed assessment including:

- **Speech Transcription**: Full text of your presentation
- **Sentiment Analysis**: The emotional tone of your words
- **Speaking Pace**: Words per minute compared to ideal ranges
- **Filler Word Detection**: Frequency and types of verbal fillers
- **Facial Expression Analysis**: Distribution of emotions detected
- **Eye Contact Measurement**: Consistency of camera engagement
- **Visual Presence**: Assessment of positioning and framing

## ü§ù Contribution Guidelines

Contributions are welcome! If you'd like to improve the AI Communication Coach:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add some amazing feature'`
4. Push to the branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## üìú License

This project is licensed under the MIT License - see the LICENSE file for details.

## üôè Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper) for speech recognition
- [Hugging Face Transformers](https://github.com/huggingface/transformers) for sentiment analysis
- [OpenCV](https://opencv.org/) for computer vision capabilities
- [Gradio](https://gradio.app/) for the interactive web interface
- [Matplotlib](https://matplotlib.org/) for data visualization

---

For questions or feedback, please open an issue on the GitHub repository.
